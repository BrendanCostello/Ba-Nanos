{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "efc10534",
   "metadata": {},
   "source": [
    "# Ba-Nanos Art Generator"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a33d76e3",
   "metadata": {},
   "source": [
    "### Import the necessary libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "caaa566e",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'torch'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[3], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mtorch\u001b[39;00m\n\u001b[1;32m      2\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mtorch\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mnn\u001b[39;00m \u001b[39mas\u001b[39;00m \u001b[39mnn\u001b[39;00m\n\u001b[1;32m      3\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mtorch\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mnn\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mfunctional\u001b[39;00m \u001b[39mas\u001b[39;00m \u001b[39mF\u001b[39;00m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'torch'"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "\n",
    "from pymongo import MongoClient\n",
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt\n",
    "import io\n",
    "import os\n",
    "\n",
    "import torchvision.transforms as transforms\n",
    "import torchvision.models as models"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "185c7b76",
   "metadata": {},
   "source": [
    "## Define the style and content layers to be used later in the code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc5009fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "content_layers_default = ['conv_4']\n",
    "style_layers_default = ['conv_1', 'conv_2', 'conv_3', 'conv_4', 'conv_5']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fad208b6",
   "metadata": {},
   "source": [
    "## Establish the connection to the MongoDB server"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aefb6401",
   "metadata": {},
   "outputs": [],
   "source": [
    "#########################################################################\n",
    "# This will need to be updated to the server where the database is hosted\n",
    "#########################################################################\n",
    "client = MongoClient('mongodb+srv://bnanos-user:LeWIpAO2oQ9uMFgg@bananos.w7ajfnm.mongodb.net/?retryWrites=true&w=majority')\n",
    "db = client['image_database']\n",
    "images_collection = db['images']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47edf068",
   "metadata": {},
   "source": [
    "## Defining Functions for Loading Images and Establishing Classes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a6a2bdb",
   "metadata": {},
   "source": [
    "### the fetch_image_from_database function is currently just a random image picker, it would be nice to change it up to be something that generates an ai image compiled from all of the images that we have in the database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60b36a34",
   "metadata": {},
   "outputs": [],
   "source": [
    "def fetch_image_from_database(image_id):\n",
    "    \n",
    "    ####################################################################\n",
    "    # This code needs to be tested once the database is linked\n",
    "    ####################################################################\n",
    "    image_document = images_collection.find_one({\"image_id\": image_id})\n",
    "    ####################################################################\n",
    "    \n",
    "    \n",
    "    if image_document:\n",
    "        image_data = image_document[\"image_data\"]\n",
    "        return image_data\n",
    "    else:\n",
    "        return None"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aecf1b48",
   "metadata": {},
   "source": [
    "### Creating a place to house the loaded image after it has been uploaded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c04acaaf",
   "metadata": {},
   "outputs": [],
   "source": [
    "def image_loader(image_data):\n",
    "    image = Image.open(io.BytesIO(image_data))\n",
    "    # Fake batch dimension required to fit network's input dimensions\n",
    "    image = loader(image).unsqueeze(0)\n",
    "    return image.to(device, torch.float)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a099b9f6",
   "metadata": {},
   "source": [
    "### The function that allows for user uploads to the style image variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2824510a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_user_image(image_path):\n",
    "    valid_extensions = ['.jpg', '.jpeg', '.png', '.pdf']\n",
    "    _, extension = os.path.splitext(image_path)\n",
    "    if extension.lower() in valid_extensions:\n",
    "        image = Image.open(image_path)\n",
    "        image = loader(image).unsqueeze(0)\n",
    "        return image.to(device, torch.float)\n",
    "    else:\n",
    "        raise ValueError(\"Invalid file format. Supported formats: .jpg, .jpeg, .png, .pdf\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44b2b338",
   "metadata": {},
   "source": [
    "## Establishing Classes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88c403c8",
   "metadata": {},
   "source": [
    "### This establishes the ContentLoss class, which establishes the initial content loss in the image generated by the database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec6809df",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ContentLoss(nn.Module):\n",
    "    def __init__(self, target):\n",
    "        super(ContentLoss, self).__init__()\n",
    "        self.target = target.detach()\n",
    "\n",
    "    def forward(self, input):\n",
    "        self.loss = F.mse_loss(input, self.target)\n",
    "        return input"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67ea5677",
   "metadata": {},
   "source": [
    "### This establishes the StyleLoss class, which determines the initial content loss in the image provided by the user that will have the generated style mapped onto it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97331e33",
   "metadata": {},
   "outputs": [],
   "source": [
    "class StyleLoss(nn.Module):\n",
    "    def __init__(self, target_feature):\n",
    "        super(StyleLoss, self).__init__()\n",
    "        self.target = gram_matrix(target_feature).detach()\n",
    "\n",
    "    def forward(self, input):\n",
    "        G = gram_matrix(input)\n",
    "        self.loss = F.mse_loss(G, self.target)\n",
    "        return input"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e48a1916",
   "metadata": {},
   "source": [
    "### Computes how gram matrices will be used for the style images. This is how we will determine the most important factors that need to be present in order for a reinterpretation to appear similar to a specific art style"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d7e479f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def gram_matrix(input):\n",
    "    a, b, c, d = input.size()\n",
    "    features = input.view(a * b, c * d)\n",
    "    G = torch.mm(features, features.t())\n",
    "    return G.div(a * b * c * d)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0545dc9d",
   "metadata": {},
   "source": [
    "### Includes the StyleLoss class and initializes the style loss using the computed gram matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84c59cb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Normalization(nn.Module):\n",
    "    def __init__(self, mean, std):\n",
    "        super(Normalization, self).__init__()\n",
    "        self.mean = torch.tensor(mean).view(-1, 1, 1)\n",
    "        self.std = torch.tensor(std).view(-1, 1, 1)\n",
    "\n",
    "    def forward(self, img):\n",
    "        return (img - self.mean) / self.std"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83af38a2",
   "metadata": {},
   "source": [
    "## Initial Train and Incorporation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7458fd84",
   "metadata": {},
   "outputs": [],
   "source": [
    "cnn = models.vgg19(pretrained=True).features.eval()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "489a3b5f",
   "metadata": {},
   "source": [
    "### Includes the normalization setup and initializes the VGG19 model with the normalization layer and incorporates the style and content layers as well as the function for building the style transfer model with the associated loss layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80fcd454",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_style_model_and_losses(cnn, normalization_mean, normalization_std,\n",
    "                               style_img, content_img,\n",
    "                               content_layers=content_layers_default,\n",
    "                               style_layers=style_layers_default):\n",
    "    normalization = Normalization(normalization_mean, normalization_std)\n",
    "\n",
    "    content_losses = []\n",
    "    style_losses = []\n",
    "    model = nn.Sequential(normalization)\n",
    "\n",
    "    i = 0\n",
    "    for layer in cnn.children():\n",
    "        if isinstance(layer, nn.Conv2d):\n",
    "            i += 1\n",
    "            name = 'conv_{}'.format(i)\n",
    "        elif isinstance(layer, nn.ReLU):\n",
    "            name = 'relu_{}'.format(i)\n",
    "            layer = nn.ReLU(inplace=False)\n",
    "        elif isinstance(layer, nn.MaxPool2d):\n",
    "            name = 'pool_{}'.format(i)\n",
    "        elif isinstance(layer, nn.BatchNorm2d):\n",
    "            name = 'bn_{}'.format(i)\n",
    "        else:\n",
    "            raise RuntimeError('Unrecognized layer: {}'.format(layer.__class__.__name__))\n",
    "\n",
    "        model.add_module(name, layer)\n",
    "\n",
    "        if name in content_layers:\n",
    "            target = model(content_img).detach()\n",
    "            content_loss = ContentLoss(target)\n",
    "            model.add_module(\"content_loss_{}\".format(i), content_loss)\n",
    "            content_losses.append(content_loss)\n",
    "\n",
    "        if name in style_layers:\n",
    "            target_feature = model(style_img).detach()\n",
    "            style_loss = StyleLoss(target_feature)\n",
    "            model.add_module(\"style_loss_{}\".format(i), style_loss)\n",
    "            style_losses.append(style_loss)\n",
    "\n",
    "    for i in range(len(model) - 1, -1, -1):\n",
    "        if isinstance(model[i], ContentLoss) or isinstance(model[i], StyleLoss):\n",
    "            break\n",
    "\n",
    "    model = model[:(i + 1)]\n",
    "\n",
    "    return model, style_losses, content_losses"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "843985df",
   "metadata": {},
   "source": [
    "### Initialize optimizer for the input image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8cc621b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_input_optimizer(input_img):\n",
    "    optimizer = optim.LBFGS([input_img])\n",
    "    return optimizer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca4ba2fe",
   "metadata": {},
   "source": [
    "### Integrates the style transfer process using the input optimizer using the provided number of steps, style weight, and content weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "873a998d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_style_transfer(cnn, normalization_mean, normalization_std,\n",
    "                       content_img, style_img, input_img, num_steps=300,\n",
    "                       style_weight=1000000, content_weight=1):\n",
    "    \"\"\"Run the style transfer.\"\"\"\n",
    "    print('Building the style transfer model..')\n",
    "    model, style_losses, content_losses = get_style_model_and_losses(cnn,\n",
    "        normalization_mean, normalization_std, style_img, content_img)\n",
    "\n",
    "    # We want to optimize the input and not the model parameters so we\n",
    "    # update all the requires_grad fields accordingly\n",
    "    input_img.requires_grad_(True)\n",
    "    # We also put the model in evaluation mode, so that specific layers\n",
    "    # such as dropout or batch normalization layers behave correctly.\n",
    "    model.eval()\n",
    "    model.requires_grad_(False)\n",
    "\n",
    "    optimizer = get_input_optimizer(input_img)\n",
    "\n",
    "    print('Optimizing..')\n",
    "    run = [0]\n",
    "    while run[0] <= num_steps:\n",
    "\n",
    "        def closure():\n",
    "            # correct the values of updated input image\n",
    "            with torch.no_grad():\n",
    "                input_img.clamp_(0, 1)\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            model(input_img)\n",
    "            style_score = 0\n",
    "            content_score = 0\n",
    "\n",
    "            for sl in style_losses:\n",
    "                style_score += sl.loss\n",
    "            for cl in content_losses:\n",
    "                content_score += cl.loss\n",
    "\n",
    "            style_score *= style_weight\n",
    "            content_score *= content_weight\n",
    "\n",
    "            loss = style_score + content_score\n",
    "            loss.backward()\n",
    "\n",
    "            run[0] += 1\n",
    "            if run[0] % 50 == 0:\n",
    "                print(\"run {}:\".format(run))\n",
    "                print('Style Loss : {:4f} Content Loss: {:4f}'.format(\n",
    "                    style_score.item(), content_score.item()))\n",
    "                print()\n",
    "\n",
    "            return style_score + content_score\n",
    "\n",
    "        optimizer.step(closure)\n",
    "\n",
    "    # a last correction...\n",
    "    with torch.no_grad():\n",
    "        input_img.clamp_(0, 1)\n",
    "\n",
    "    return input_img"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "869c1199",
   "metadata": {},
   "source": [
    "### This loop puts it all together and prints the output after converting the image into a number that can be used (between 0 and 1) to convert images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8f79f3c",
   "metadata": {},
   "outputs": [
    {
     "ename": "ServerSelectionTimeoutError",
     "evalue": "localhost:27017: [Errno 61] Connection refused, Timeout: 30s, Topology Description: <TopologyDescription id: 64e3f2c1dd8ee1f015a268d9, topology_type: Unknown, servers: [<ServerDescription ('localhost', 27017) server_type: Unknown, rtt: None, error=AutoReconnect('localhost:27017: [Errno 61] Connection refused')>]>",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mServerSelectionTimeoutError\u001b[0m               Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/gf/0_8jxzcx2p54tfxnbprqq9xr0000gn/T/ipykernel_81964/4176940610.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     26\u001b[0m     \u001b[0;31m#####################################################################################\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m     \u001b[0mimage_id\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m1\u001b[0m  \u001b[0;31m# Replace with the appropriate image ID from your database\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 28\u001b[0;31m     \u001b[0mstyle_img_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfetch_image_from_database\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimage_id\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     29\u001b[0m     \u001b[0;31m#####################################################################################\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     30\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/var/folders/gf/0_8jxzcx2p54tfxnbprqq9xr0000gn/T/ipykernel_81964/3957857529.py\u001b[0m in \u001b[0;36mfetch_image_from_database\u001b[0;34m(image_id)\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0;31m# This code needs to be tested once the database is linked\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0;31m####################################################################\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m     \u001b[0mimage_document\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mimages_collection\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfind_one\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0;34m\"image_id\"\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mimage_id\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m     \u001b[0;31m####################################################################\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/pymongo/collection.py\u001b[0m in \u001b[0;36mfind_one\u001b[0;34m(self, filter, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1468\u001b[0m             \u001b[0mfilter\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m\"_id\"\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mfilter\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1469\u001b[0m         \u001b[0mcursor\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfind\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilter\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1470\u001b[0;31m         \u001b[0;32mfor\u001b[0m \u001b[0mresult\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mcursor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlimit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1471\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1472\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/pymongo/cursor.py\u001b[0m in \u001b[0;36mnext\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1249\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__empty\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1250\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mStopIteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1251\u001b[0;31m         \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__data\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_refresh\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1252\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__data\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpopleft\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1253\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/pymongo/cursor.py\u001b[0m in \u001b[0;36m_refresh\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1140\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1141\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__session\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1142\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__session\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__collection\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdatabase\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclient\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_ensure_session\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1143\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1144\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__id\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# Query\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/pymongo/mongo_client.py\u001b[0m in \u001b[0;36m_ensure_session\u001b[0;34m(self, session)\u001b[0m\n\u001b[1;32m   1756\u001b[0m             \u001b[0;31m# Don't make implicit sessions causally consistent. Applications\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1757\u001b[0m             \u001b[0;31m# should always opt-in.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1758\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__start_session\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcausal_consistency\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1759\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mConfigurationError\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mInvalidOperation\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1760\u001b[0m             \u001b[0;31m# Sessions not supported.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/pymongo/mongo_client.py\u001b[0m in \u001b[0;36m__start_session\u001b[0;34m(self, implicit, **kwargs)\u001b[0m\n\u001b[1;32m   1701\u001b[0m         \u001b[0;31m# Raises ConfigurationError if sessions are not supported.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1702\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mimplicit\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1703\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_topology\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_check_implicit_session_support\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1704\u001b[0m             \u001b[0mserver_session\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_EmptyServerSession\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1705\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/pymongo/topology.py\u001b[0m in \u001b[0;36m_check_implicit_session_support\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    536\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_check_implicit_session_support\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    537\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 538\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_check_session_support\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    539\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    540\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_check_session_support\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/pymongo/topology.py\u001b[0m in \u001b[0;36m_check_session_support\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    552\u001b[0m                     )\n\u001b[1;32m    553\u001b[0m             \u001b[0;32melif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_description\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreadable_servers\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 554\u001b[0;31m                 self._select_servers_loop(\n\u001b[0m\u001b[1;32m    555\u001b[0m                     \u001b[0mreadable_server_selector\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_server_selection_timeout\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    556\u001b[0m                 )\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/pymongo/topology.py\u001b[0m in \u001b[0;36m_select_servers_loop\u001b[0;34m(self, selector, timeout, address)\u001b[0m\n\u001b[1;32m    236\u001b[0m             \u001b[0;31m# No suitable servers.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    237\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mtimeout\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mnow\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0mend_time\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 238\u001b[0;31m                 raise ServerSelectionTimeoutError(\n\u001b[0m\u001b[1;32m    239\u001b[0m                     \u001b[0;34mf\"{self._error_message(selector)}, Timeout: {timeout}s, Topology Description: {self.description!r}\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    240\u001b[0m                 )\n",
      "\u001b[0;31mServerSelectionTimeoutError\u001b[0m: localhost:27017: [Errno 61] Connection refused, Timeout: 30s, Topology Description: <TopologyDescription id: 64e3f2c1dd8ee1f015a268d9, topology_type: Unknown, servers: [<ServerDescription ('localhost', 27017) server_type: Unknown, rtt: None, error=AutoReconnect('localhost:27017: [Errno 61] Connection refused')>]>"
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    # Set device for PyTorch\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    torch.set_default_device(device)\n",
    "    \n",
    "    # Initialize the VGG19 model\n",
    "    cnn = models.vgg19(pretrained=True).features.eval()\n",
    "    \n",
    "    # Initialize normalization\n",
    "    cnn_normalization_mean = torch.tensor([0.485, 0.456, 0.406])\n",
    "    cnn_normalization_std = torch.tensor([0.229, 0.224, 0.225])\n",
    "    normalization = Normalization(cnn_normalization_mean, cnn_normalization_std)\n",
    "    \n",
    "    # Initialize content and style layers\n",
    "    content_layers_default = ['conv_4']\n",
    "    style_layers_default = ['conv_1', 'conv_2', 'conv_3', 'conv_4', 'conv_5']\n",
    "    \n",
    "    # Desired size of the output image\n",
    "    imsize = 512 if torch.cuda.is_available() else 128  # use small size if no GPU\n",
    "    \n",
    "    loader = transforms.Compose([\n",
    "        transforms.Resize(imsize),  # scale imported image\n",
    "        transforms.ToTensor()])  # transform it into a torch tensor\n",
    "    \n",
    "    \n",
    "    #####################################################################################\n",
    "    image_id = 1  # Replace with the appropriate image ID from your database\n",
    "    style_img_data = fetch_image_from_database(image_id)\n",
    "    #####################################################################################\n",
    "    \n",
    "    \n",
    "    if style_img_data:\n",
    "        style_img = image_loader(style_img_data)\n",
    "        \n",
    "        # Get user-provided content image\n",
    "        content_image_path = input(\"Enter path to content image (.jpg, .png, or .pdf): \")\n",
    "        try:\n",
    "            content_img = load_user_image(content_image_path)\n",
    "            \n",
    "            assert style_img.size() == content_img.size(), \\\n",
    "                \"We need to import style and content images of the same size\"\n",
    "            \n",
    "            # Initialize input image\n",
    "            input_img = content_img.clone()\n",
    "            \n",
    "            # Display input, style, and content images using Matplotlib\n",
    "            unloader = transforms.ToPILImage()  # reconvert into PIL image\n",
    "            plt.ion()\n",
    "            \n",
    "            def imshow(tensor, title=None):\n",
    "                image = tensor.cpu().clone()\n",
    "                image = image.squeeze(0)\n",
    "                image = unloader(image)\n",
    "                plt.imshow(image)\n",
    "                if title is not None:\n",
    "                    plt.title(title)\n",
    "                plt.pause(0.001)\n",
    "            \n",
    "            plt.figure()\n",
    "            imshow(input_img, title='Input Image')\n",
    "            \n",
    "            plt.figure()\n",
    "            imshow(style_img, title='Style Image')\n",
    "            \n",
    "            plt.figure()\n",
    "            imshow(content_img, title='Content Image')\n",
    "            \n",
    "            # Run style transfer\n",
    "            output = run_style_transfer(\n",
    "                cnn, cnn_normalization_mean, cnn_normalization_std,\n",
    "                content_img, style_img, input_img\n",
    "            )\n",
    "            \n",
    "            # Display the final output image\n",
    "            plt.figure()\n",
    "            imshow(output, title='Output Image')\n",
    "            plt.show()\n",
    "            \n",
    "            # Display the output image\n",
    "            plt.figure()\n",
    "            imshow(output, title='Output Image')\n",
    "            \n",
    "            plt.ioff()\n",
    "            plt.show()\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(\"Error:\", str(e))\n",
    "    else:\n",
    "        print(\"Image not found in the database.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec66dd26",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
